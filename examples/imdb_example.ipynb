{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary modules for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import h5py\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "np.random.seed(0) # for reproducibility\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,5,6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/amr1/anaconda2/lib/python2.7/site-packages/keras/datasets/imdb.py:44: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000  sequences\n",
      "Pad sequences (samples x time)\n"
     ]
    }
   ],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n",
    "\n",
    "print('Loading data...')\n",
    "(X_set1, y_set1), (X_set2, y_set2) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_set1)+len(X_set2), ' sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_set1 = sequence.pad_sequences(X_set1, maxlen=maxlen)\n",
    "X_set2 = sequence.pad_sequences(X_set2, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training set into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20000, 400)\n",
      "X_valid shape: (10000, 400)\n",
      "X_test shape: (20000, 400)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_set1[:20000]\n",
    "y_train = y_set1[:20000]\n",
    "X_valid = np.concatenate((X_set1[20000:], X_set2[:5000]), axis=0)\n",
    "y_valid = np.concatenate((y_set1[20000:], y_set2[:5000]), axis=0)\n",
    "X_test = X_set2[5000:]\n",
    "y_test = y_set2[5000:]\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_valid shape:', X_valid.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model (the architecture ships with Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /users/amr1/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1008: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /users/amr1/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 26s - loss: 0.4196 - acc: 0.7911 - val_loss: 0.2892 - val_acc: 0.8787\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 26s - loss: 0.2476 - acc: 0.8985 - val_loss: 0.2777 - val_acc: 0.8844\n"
     ]
    }
   ],
   "source": [
    "# Building the model that ships with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_valid, y_valid))\n",
    "model.save(\"imdb_model_k2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute model outputs (with and without test-time dropout) on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On validation set\n",
      "Computing deterministic activations\n",
      "Computing nondeterministic activations\n",
      "Done 10 runs\n",
      "Done 20 runs\n",
      "Done 30 runs\n",
      "Done 40 runs\n",
      "Done 50 runs\n",
      "Done 60 runs\n",
      "Done 70 runs\n",
      "Done 80 runs\n",
      "Done 90 runs\n",
      "Done 100 runs\n",
      "On testing set\n",
      "Computing deterministic activations\n",
      "Computing nondeterministic activations\n",
      "Done 10 runs\n",
      "Done 20 runs\n",
      "Done 30 runs\n",
      "Done 40 runs\n",
      "Done 50 runs\n",
      "Done 60 runs\n",
      "Done 70 runs\n",
      "Done 80 runs\n",
      "Done 90 runs\n",
      "Done 100 runs\n"
     ]
    }
   ],
   "source": [
    "import abstention as ab\n",
    "\n",
    "num_dropout_runs = 100 #the number of runs to use with test-time dropout\n",
    "batch_size = 50\n",
    "task_idx = 0 #output task to evaluate abstention metrics for\n",
    "\n",
    "#preact_func returns the output prior to the final sigmoid nonlinearity, given the input\n",
    "preact_func = ab.util.get_preact_func(model=model, task_idx=task_idx)\n",
    "\n",
    "#Compute the output on the validation set pre-activation, both without test-time\n",
    "#dropout and with test-time dropout enabled\n",
    "print(\"On validation set\")\n",
    "valid_preacts, valid_dropout_preacts = ab.util.obtain_raw_data(\n",
    "    preact_func=preact_func,\n",
    "    data=X_valid,\n",
    "    num_dropout_runs=num_dropout_runs,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "#Do the same for the testing set\n",
    "print(\"On testing set\")\n",
    "test_preacts, test_dropout_preacts = ab.util.obtain_raw_data(\n",
    "    preact_func=preact_func, data=X_test, num_dropout_runs=num_dropout_runs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put model outputs through calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platt scaling coef: 1.010432843598933 ; intercept: -0.6110752598492817\n"
     ]
    }
   ],
   "source": [
    "cb_method_name_to_factory = OrderedDict([\n",
    "    #Expit is just the sigmoid; no calibration\n",
    "    (\"uncalibrated_posterior\", ab.calibration.Expit()),\n",
    "    (\"platt_calibrated_posterior\", ab.calibration.PlattScaling()),\n",
    "])\n",
    "\n",
    "(cb_method_name_to_valid_posterior_prob,\n",
    " cb_method_name_to_test_posterior_prob,\n",
    " transform_name_to_valid_uncert,\n",
    " transform_name_to_test_uncert) = ab.util.obtain_posterior_probs_and_uncert_estimates(\n",
    "                                    cb_method_name_to_factory=cb_method_name_to_factory,\n",
    "                                    valid_labels=y_valid,\n",
    "                                    valid_preacts=valid_preacts,\n",
    "                                    valid_dropout_preacts=valid_dropout_preacts,\n",
    "                                    test_preacts=test_preacts,\n",
    "                                    test_dropout_preacts=test_dropout_preacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cb_method_name_to_valid_posterior_prob` and `cb_method_name_to_test_posterior_prob` have keys of:\n",
    "- `uncalibrated_posterior` which has the uncalibrated (i.e.) the original probabilities\n",
    "- `platt_calibrated_posterior` which has the calibrated probabilities using platt scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transform_name_to_valid_uncert` and `transform_name_to_test_uncert` have keys of:\n",
    "- `preactivation_uncertainty`, which has the population standard deviation computed on the output before the final nonlinearity\n",
    "- `uncalibrated_posterior_uncertainty`, which has the population standard deviation computed on the uncertainties output after the final nonlinearity, but without any calibration applied\n",
    "- `platt_calibrated_posterior_uncertainty`, which has the population standard deviation computed on the uncertainties output after the final nonlinearity and after calibration is applied using Platt scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import sklearn.calibration\n",
    "\n",
    "platt_frac_pos, platt_mean_pred_val = sklearn.calibration.calibration_curve(\n",
    "        y_true=y_valid,\n",
    "        y_prob=cb_method_name_to_valid_posterior_prob['platt_calibrated_posterior'],\n",
    "        normalize=False, n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import abstention\n",
    "reload(abstention.abstention)\n",
    "from abstention.abstention import AuPrcAbstentionEval, AuRocAbstentionEval\n",
    "from abstention.abstention import (FixedThreshold, RandomAbstention,\n",
    "                                   NegPosteriorDistanceFromThreshold,\n",
    "                                   Uncertainty,\n",
    "                                   MarginalDeltaAuRoc, MarginalDeltaAuPrc,\n",
    "                                   RecursiveMarginalDeltaAuRoc,\n",
    "                                   RecursiveMarginalDeltaAuPrc)\n",
    "from collections import namedtuple\n",
    "\n",
    "AbstentionFuncInfo = namedtuple('AbstentionFuncInfo',\n",
    "                                ('method_name','factory', 'posterior', 'uncert'))\n",
    "\n",
    "proportion_to_retain = 0.95\n",
    "evaluation_functions = OrderedDict([('auPRC',AuPrcAbstentionEval(proportion_to_retain)),\n",
    "                                    ('auROC',AuRocAbstentionEval(proportion_to_retain))])\n",
    "\n",
    "num_positives = np.sum(y_train)+np.sum(y_valid)\n",
    "imbalance = (len(y_train)+len(y_valid)-num_positives)/float(num_positives)\n",
    "\n",
    "abstention_func_infos = [\n",
    "         AbstentionFuncInfo(method_name='random', factory=RandomAbstention(),\n",
    "                            posterior='platt_calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='calibrated_marginal_auroc',\n",
    "                            factory=MarginalDeltaAuRoc(),\n",
    "                            posterior='platt_calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='calibrated_marginal_auprc',\n",
    "                            factory=MarginalDeltaAuPrc(),\n",
    "                            posterior='platt_calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='uncalibrated_prob_distance_point_five',\n",
    "                            factory=NegPosteriorDistanceFromThreshold(FixedThreshold(0.5)),\n",
    "                            posterior='uncalibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='calibrated_prob_distance_point_five',\n",
    "                            factory=NegPosteriorDistanceFromThreshold(FixedThreshold(0.5)),\n",
    "                            posterior='platt_calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='preactivation_uncertainty',\n",
    "                            factory=Uncertainty(),\n",
    "                            posterior='uncalibrated_posterior', uncert='preactivation'),\n",
    "         AbstentionFuncInfo(method_name='uncalibrated_posterior_uncertainty',\n",
    "                            factory=Uncertainty(),\n",
    "                            posterior='uncalibrated_posterior', uncert='uncalibrated_posterior'),\n",
    "         AbstentionFuncInfo(method_name='calibrated_posterior_uncertainty',\n",
    "                            factory=Uncertainty(),\n",
    "                            posterior='uncalibrated_posterior', uncert='platt_calibrated_posterior')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calling method random\n",
      "\n",
      "Calling method calibrated_marginal_auroc\n",
      "valid est metric 0.9577813763154428\n",
      "data est metric 0.9559907651869655\n",
      "valid est metric 0.9577813763154428\n",
      "data est metric 0.9574339675295698\n",
      "\n",
      "Calling method calibrated_marginal_auprc\n",
      "valid est metric 0.9564477426081814\n",
      "data est metric 0.9535672687991844\n",
      "valid est metric 0.9564477426081814\n",
      "data est metric 0.9542574597727642\n",
      "\n",
      "Calling method uncalibrated_prob_distance_point_five\n",
      "\n",
      "Calling method calibrated_prob_distance_point_five\n",
      "\n",
      "Calling method preactivation_uncertainty\n",
      "\n",
      "Calling method uncalibrated_posterior_uncertainty\n",
      "\n",
      "Calling method calibrated_posterior_uncertainty\n"
     ]
    }
   ],
   "source": [
    "metric_to_method_name_to_test_perfs = OrderedDict()\n",
    "metric_to_method_name_to_valid_perfs = OrderedDict()\n",
    "for metric_name in evaluation_functions:\n",
    "    method_name_to_test_perfs = OrderedDict([\n",
    "            (abstention_func.method_name, []) for abstention_func in abstention_func_infos])\n",
    "    method_name_to_valid_perfs = OrderedDict([\n",
    "            (abstention_func.method_name, []) for abstention_func in abstention_func_infos])\n",
    "    metric_to_method_name_to_test_perfs[metric_name] = method_name_to_test_perfs\n",
    "    metric_to_method_name_to_valid_perfs[metric_name] = method_name_to_valid_perfs\n",
    "\n",
    "for abstention_func_info in abstention_func_infos:\n",
    "    print(\"\\nCalling method\", abstention_func_info.method_name)\n",
    "    factory = abstention_func_info.factory\n",
    "    posterior_name = abstention_func_info.posterior\n",
    "    uncert_name = abstention_func_info.uncert   \n",
    "\n",
    "    valid_posterior = cb_method_name_to_valid_posterior_prob[posterior_name]\n",
    "    test_posterior = cb_method_name_to_test_posterior_prob[posterior_name]\n",
    "    valid_uncert = transform_name_to_valid_uncert[uncert_name] if uncert_name else None\n",
    "    test_uncert = transform_name_to_test_uncert[uncert_name] if uncert_name else None\n",
    "    \n",
    "    abstention_func = factory(valid_labels=y_valid,\n",
    "                              valid_posterior=valid_posterior,\n",
    "                              valid_uncert=valid_uncert)\n",
    "    test_abstention_scores = abstention_func(posterior_probs=test_posterior,\n",
    "                                             uncertainties=test_uncert)\n",
    "    valid_abstention_scores = abstention_func(posterior_probs=valid_posterior,\n",
    "                                              uncertainties=valid_uncert)\n",
    "    for evaluation_func_name, evaluation_func in evaluation_functions.items():\n",
    "        valid_perf = evaluation_func(abstention_scores=valid_abstention_scores,\n",
    "                                                            y_true=y_valid, y_score=valid_posterior)\n",
    "        test_perf = evaluation_func(abstention_scores=test_abstention_scores,\n",
    "                                                            y_true=y_test, y_score=test_posterior)\n",
    "        metric_to_method_name_to_test_perfs[evaluation_func_name]\\\n",
    "                                      [abstention_func_info.method_name].append(test_perf)\n",
    "        metric_to_method_name_to_valid_perfs[evaluation_func_name]\\\n",
    "                                      [abstention_func_info.method_name].append(valid_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best auROC methods - test\n",
      "AuROC ranks:\n",
      "('calibrated_marginal_auroc', 0), average auROC = 0.9594569584487534\n",
      "('calibrated_prob_distance_point_five', 1), average auROC = 0.9594419735971772\n",
      "('calibrated_marginal_auprc', 2), average auROC = 0.9593564954958288\n",
      "('calibrated_posterior_uncertainty', 3), average auROC = 0.959317798185798\n",
      "('uncalibrated_posterior_uncertainty', 4), average auROC = 0.9585043518572365\n",
      "('uncalibrated_prob_distance_point_five', 5), average auROC = 0.9585003604979381\n",
      "('preactivation_uncertainty', 6), average auROC = 0.9550453860182624\n",
      "('random', 7), average auROC = 0.9522179216047506\n",
      "\n",
      "Best auPRC methods - test\n",
      "AuPRC ranks:\n",
      "('calibrated_marginal_auprc', 0), average auPRC = 0.9569414386015427\n",
      "('calibrated_prob_distance_point_five', 1), average auPRC = 0.956921591776704\n",
      "('calibrated_marginal_auroc', 2), average auPRC = 0.9568865103881449\n",
      "('calibrated_posterior_uncertainty', 3), average auPRC = 0.9568526143158497\n",
      "('uncalibrated_prob_distance_point_five', 4), average auPRC = 0.9565625929708991\n",
      "('uncalibrated_posterior_uncertainty', 5), average auPRC = 0.9565504554943488\n",
      "('preactivation_uncertainty', 6), average auPRC = 0.954071782809122\n",
      "('random', 7), average auPRC = 0.950428930693436\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "print(\"\\nBest auROC methods - test\")\n",
    "metric_to_auroc_test_score = defaultdict(lambda: 0)\n",
    "metric_name_ranks = sorted(metric_to_method_name_to_test_perfs['auROC'].keys(),\n",
    "                           key=lambda x: -metric_to_method_name_to_test_perfs['auROC'][x][0])\n",
    "for idx, name in enumerate(metric_name_ranks):\n",
    "        metric_to_auroc_test_score[name] += idx\n",
    "print(\"AuROC ranks:\")\n",
    "print(\"\\n\".join(str(x)\n",
    "                +\", average auROC = \"\n",
    "                +str(np.mean(metric_to_method_name_to_test_perfs['auROC'][x[0]]))\n",
    "                for x in sorted(metric_to_auroc_test_score.items(), key=lambda x: x[1])))\n",
    "\n",
    "print(\"\\nBest auPRC methods - test\")\n",
    "metric_to_auprc_test_score = defaultdict(lambda: 0)\n",
    "metric_name_ranks = sorted(metric_to_method_name_to_test_perfs['auPRC'].keys(),\n",
    "                           key=lambda x: -metric_to_method_name_to_test_perfs['auPRC'][x][0])\n",
    "for idx, name in enumerate(metric_name_ranks):\n",
    "        metric_to_auprc_test_score[name] += idx\n",
    "print(\"AuPRC ranks:\")\n",
    "print(\"\\n\".join(str(x)\n",
    "                +\", average auPRC = \"\n",
    "                +str(np.mean(metric_to_method_name_to_test_perfs['auPRC'][x[0]]))\n",
    "                for x in sorted(metric_to_auprc_test_score.items(), key=lambda x: x[1])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
