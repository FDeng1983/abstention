{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary modules for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "(25000, 'train sequences')\n",
      "(25000, 'test sequences')\n",
      "Pad sequences (samples x time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avantishrikumar/keras/keras/datasets/imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training set into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (20000, 400))\n",
      "('X_valid shape:', (5000, 400))\n",
      "('X_test shape:', (25000, 400))\n"
     ]
    }
   ],
   "source": [
    "X_valid = X_train[20000:]\n",
    "y_valid = y_train[20000:]\n",
    "X_train = X_train[:20000]\n",
    "y_train = y_train[:20000]\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_valid shape:', X_valid.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model (the architecture ships with Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building the model; architecture ships with Keras\n",
    "\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "nb_epoch = 2\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen,\n",
    "                    dropout=0.2))\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          validation_data=(X_valid, y_valid))\n",
    "model.save(\"imdb.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute model outputs (with and without test-time dropout) on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On validation set\n",
      "Computing deterministic activations\n",
      "Computing nondeterministic activations\n",
      "On testing set\n",
      "Computing deterministic activations\n",
      "Computing nondeterministic activations\n"
     ]
    }
   ],
   "source": [
    "import abstention as ab\n",
    "\n",
    "num_dropout_runs = 100 #the number of runs to use with test-time dropout\n",
    "batch_size = 50\n",
    "task_idx = 0 #output task to evaluate abstention metrics for\n",
    "\n",
    "#preact_func returns the output prior to the final sigmoid nonlinearity, given the input\n",
    "preact_func = ab.util.get_preact_func(model=model, task_idx=task_idx)\n",
    "\n",
    "#Compute the output on the validation set pre-activation, both without test-time\n",
    "#dropout and with test-time dropout enabled\n",
    "print(\"On validation set\")\n",
    "valid_preacts, valid_dropout_preacts = ab.util.obtain_raw_data(\n",
    "    preact_func=preact_func,\n",
    "    data=X_valid,\n",
    "    num_dropout_runs=num_dropout_runs,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "#Do the same for the testing set\n",
    "print(\"On testing set\")\n",
    "test_preacts, test_dropout_preacts = ab.util.obtain_raw_data(\n",
    "    preact_func=preact_func, data=X_test, num_dropout_runs=num_dropout_runs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put model outputs through calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb_method_name_to_factory = OrderedDict([\n",
    "    #Expit is just the sigmoid; no calibration\n",
    "    (\"uncalibrated_posterior\", ab.calibration.Expit()),\n",
    "    (\"calibrated_posterior\", ab.calibration.IsotonicRegression())\n",
    "    #To use Platt scaling for calibration\n",
    "    #rather than Isotonic Regression, uncomment the line below\n",
    "    #and comment out the line above\n",
    "    #(\"calibrated_posterior\", ab.calibration.PlattScaling()),\n",
    "])\n",
    "\n",
    "(cb_method_name_to_valid_posterior_prob,\n",
    " cb_method_name_to_test_posterior_prob,\n",
    " transform_name_to_valid_uncert,\n",
    " transform_name_to_test_uncert) = ab.util.obtain_posterior_probs_and_uncert_estimates(\n",
    "                                    cb_method_name_to_factory=cb_method_name_to_factory,\n",
    "                                    valid_labels=y_valid,\n",
    "                                    valid_preacts=valid_preacts,\n",
    "                                    valid_dropout_preacts=valid_dropout_preacts,\n",
    "                                    test_preacts=test_preacts,\n",
    "                                    test_dropout_preacts=test_dropout_preacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cb_method_name_to_valid_posterior_prob` and `cb_method_name_to_test_posterior_prob` have keys of:\n",
    "- `uncalibrated_posterior` which has the uncalibrated (i.e.) the original probabilities\n",
    "- `calibrated_posterior` which has the calibrated probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uncalibrated_posterior', 'calibrated_posterior']\n",
      "['uncalibrated_posterior', 'calibrated_posterior']\n"
     ]
    }
   ],
   "source": [
    "print(cb_method_name_to_valid_posterior_prob.keys())\n",
    "print(cb_method_name_to_test_posterior_prob.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transform_name_to_valid_uncert` and `transform_name_to_test_uncert` have keys of:\n",
    "- `preactivation_uncertainty`, which has the population standard deviation computed on the output before the final nonlinearity\n",
    "- `uncalibrated_posterior_uncertainty`, which has the population standard deviation computed on the uncertainties output after the final nonlinearity, but without any calibration applied\n",
    "- `calibrated_posterior_uncertainty`, which has the population standard deviation computed on the uncertainties output after the final nonlinearity and after calibration is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preactivation', 'uncalibrated_posterior', 'calibrated_posterior']\n",
      "['preactivation', 'uncalibrated_posterior', 'calibrated_posterior']\n"
     ]
    }
   ],
   "source": [
    "print(transform_name_to_valid_uncert.keys())\n",
    "print(transform_name_to_test_uncert.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess the quality of the calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import abstention\n",
    "reload(abstention.abstention)\n",
    "from abstention.abstention import AuPrcAbstentionEval, AuRocAbstentionEval\n",
    "from abstention.abstention import (FixedThreshold, RandomAbstention,\n",
    "                                   NegPosteriorDistanceFromThreshold,\n",
    "                                   Uncertainty,\n",
    "                                   MarginalDeltaAuRoc, MarginalDeltaAuPrc,\n",
    "                                   RecursiveMarginalDeltaAuRoc,\n",
    "                                   RecursiveMarginalDeltaAuPrc)\n",
    "from collections import namedtuple\n",
    "\n",
    "AbstentionFuncInfo = namedtuple('AbstentionFuncInfo',\n",
    "                                ('method_name','factory', 'posterior', 'uncert'))\n",
    "\n",
    "proportion_to_retain = 0.95\n",
    "evaluation_functions = OrderedDict([('auPRC',AuPrcAbstentionEval(proportion_to_retain)),\n",
    "                                    ('auROC',AuRocAbstentionEval(proportion_to_retain))])\n",
    "\n",
    "num_positives = np.sum(y_train)+np.sum(y_valid)\n",
    "imbalance = (len(y_train)+len(y_valid)-num_positives)/float(num_positives)\n",
    "\n",
    "abstention_func_infos = [\n",
    "         AbstentionFuncInfo(method_name='random', factory=RandomAbstention(),\n",
    "                            posterior='calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='calibrated_marginal_auroc',\n",
    "                            factory=MarginalDeltaAuRoc(),\n",
    "                            posterior='calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='calibrated_marginal_auprc',\n",
    "                            factory=MarginalDeltaAuPrc(),\n",
    "                            posterior='calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='recursive_calibrated_marginal_auroc',\n",
    "                            factory=RecursiveMarginalDeltaAuRoc(proportion_to_retain),\n",
    "                            posterior='calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='recursive_calibrated_marginal_auprc',\n",
    "                            factory=RecursiveMarginalDeltaAuPrc(proportion_to_retain),\n",
    "                            posterior='calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='uncalibrated_prob_distance_point_five',\n",
    "                            factory=NegPosteriorDistanceFromThreshold(FixedThreshold(0.5)),\n",
    "                            posterior='uncalibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='calibrated_prob_distance_point_five',\n",
    "                            factory=NegPosteriorDistanceFromThreshold(FixedThreshold(0.5)),\n",
    "                            posterior='calibrated_posterior', uncert=None),\n",
    "         AbstentionFuncInfo(method_name='preactivation_uncertainty',\n",
    "                            factory=Uncertainty(),\n",
    "                            posterior='uncalibrated_posterior', uncert='preactivation'),\n",
    "         AbstentionFuncInfo(method_name='uncalibrated_posterior_uncertainty',\n",
    "                            factory=Uncertainty(),\n",
    "                            posterior='uncalibrated_posterior', uncert='uncalibrated_posterior'),\n",
    "         AbstentionFuncInfo(method_name='calibrated_posterior_uncertainty',\n",
    "                            factory=Uncertainty(),\n",
    "                            posterior='uncalibrated_posterior', uncert='calibrated_posterior')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calling method random\n",
      "\n",
      "Calling method calibrated_marginal_auroc\n",
      "valid est metric 0.960282453029978\n",
      "data est metric 0.9575382192609952\n",
      "valid est metric 0.960282453029978\n",
      "data est metric 0.9602537114917256\n",
      "\n",
      "Calling method calibrated_marginal_auprc\n",
      "valid est metric 0.9605970235228414\n",
      "data est metric 0.958125530953775\n",
      "valid est metric 0.9605970235228414\n",
      "data est metric 0.9604364880966818\n",
      "\n",
      "Calling method recursive_calibrated_marginal_auroc\n",
      "Items recursively evicted: 0 of 1250\n",
      "Items recursively evicted: 100 of 1250\n",
      "Items recursively evicted: 200 of 1250\n",
      "Items recursively evicted: 300 of 1250\n",
      "Items recursively evicted: 400 of 1250\n",
      "Items recursively evicted: 500 of 1250\n",
      "Items recursively evicted: 600 of 1250\n",
      "Items recursively evicted: 700 of 1250\n",
      "Items recursively evicted: 800 of 1250\n",
      "Items recursively evicted: 900 of 1250\n",
      "Items recursively evicted: 1000 of 1250\n",
      "Items recursively evicted: 1100 of 1250\n",
      "Items recursively evicted: 1200 of 1250\n",
      "Items recursively evicted: 0 of 250\n",
      "Items recursively evicted: 100 of 250\n",
      "Items recursively evicted: 200 of 250\n",
      "\n",
      "Calling method recursive_calibrated_marginal_auprc\n",
      "Items recursively evicted: 0 of 1250\n",
      "Items recursively evicted: 100 of 1250\n",
      "Items recursively evicted: 200 of 1250\n",
      "Items recursively evicted: 300 of 1250\n",
      "Items recursively evicted: 400 of 1250\n",
      "Items recursively evicted: 500 of 1250\n",
      "Items recursively evicted: 600 of 1250\n",
      "Items recursively evicted: 700 of 1250\n",
      "Items recursively evicted: 800 of 1250\n",
      "Items recursively evicted: 900 of 1250\n",
      "Items recursively evicted: 1000 of 1250\n",
      "Items recursively evicted: 1100 of 1250\n",
      "Items recursively evicted: 1200 of 1250\n",
      "Items recursively evicted: 0 of 250\n",
      "Items recursively evicted: 100 of 250\n",
      "Items recursively evicted: 200 of 250\n",
      "\n",
      "Calling method uncalibrated_prob_distance_point_five\n",
      "\n",
      "Calling method calibrated_prob_distance_point_five\n",
      "\n",
      "Calling method preactivation_uncertainty\n",
      "\n",
      "Calling method uncalibrated_posterior_uncertainty\n",
      "\n",
      "Calling method calibrated_posterior_uncertainty\n"
     ]
    }
   ],
   "source": [
    "metric_to_method_name_to_test_perfs = OrderedDict()\n",
    "metric_to_method_name_to_valid_perfs = OrderedDict()\n",
    "for metric_name in evaluation_functions:\n",
    "    method_name_to_test_perfs = OrderedDict([\n",
    "            (abstention_func.method_name, []) for abstention_func in abstention_func_infos])\n",
    "    method_name_to_valid_perfs = OrderedDict([\n",
    "            (abstention_func.method_name, []) for abstention_func in abstention_func_infos])\n",
    "    metric_to_method_name_to_test_perfs[metric_name] = method_name_to_test_perfs\n",
    "    metric_to_method_name_to_valid_perfs[metric_name] = method_name_to_valid_perfs\n",
    "\n",
    "for abstention_func_info in abstention_func_infos:\n",
    "    print(\"\\nCalling method\", abstention_func_info.method_name)\n",
    "    factory = abstention_func_info.factory\n",
    "    posterior_name = abstention_func_info.posterior\n",
    "    uncert_name = abstention_func_info.uncert   \n",
    "\n",
    "    valid_posterior = cb_method_name_to_valid_posterior_prob[posterior_name]\n",
    "    test_posterior = cb_method_name_to_test_posterior_prob[posterior_name]\n",
    "    valid_uncert = transform_name_to_valid_uncert[uncert_name] if uncert_name else None\n",
    "    test_uncert = transform_name_to_test_uncert[uncert_name] if uncert_name else None\n",
    "    \n",
    "    abstention_func = factory(valid_labels=y_valid,\n",
    "                              valid_posterior=valid_posterior,\n",
    "                              valid_uncert=valid_uncert)\n",
    "    test_abstention_scores = abstention_func(posterior_probs=test_posterior,\n",
    "                                             uncertainties=test_uncert)\n",
    "    valid_abstention_scores = abstention_func(posterior_probs=valid_posterior,\n",
    "                                              uncertainties=valid_uncert)\n",
    "    for evaluation_func_name, evaluation_func in evaluation_functions.items():\n",
    "        valid_perf = evaluation_func(abstention_scores=valid_abstention_scores,\n",
    "                                                            y_true=y_valid, y_score=valid_posterior)\n",
    "        test_perf = evaluation_func(abstention_scores=test_abstention_scores,\n",
    "                                                            y_true=y_test, y_score=test_posterior)\n",
    "        metric_to_method_name_to_test_perfs[evaluation_func_name]\\\n",
    "                                      [abstention_func_info.method_name].append(test_perf)\n",
    "        metric_to_method_name_to_valid_perfs[evaluation_func_name]\\\n",
    "                                      [abstention_func_info.method_name].append(valid_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best auROC methods - test\n",
      "AuROC ranks:\n",
      "('uncalibrated_prob_distance_point_five', 0), average auROC = 0.9625964121206624\n",
      "('recursive_calibrated_marginal_auroc', 1), average auROC = 0.9622659762465997\n",
      "('calibrated_marginal_auroc', 2), average auROC = 0.9622659591203069\n",
      "('calibrated_marginal_auprc', 3), average auROC = 0.9622655493609823\n",
      "('calibrated_prob_distance_point_five', 4), average auROC = 0.9622651664234967\n",
      "('recursive_calibrated_marginal_auprc', 5), average auROC = 0.9622140108050581\n",
      "('uncalibrated_posterior_uncertainty', 6), average auROC = 0.9620578487322516\n",
      "('calibrated_posterior_uncertainty', 7), average auROC = 0.9613345225887615\n",
      "('random', 8), average auROC = 0.9554392771476534\n",
      "('preactivation_uncertainty', 9), average auROC = 0.9525146129085712\n",
      "\n",
      "Best auPRC methods - test\n",
      "AuPRC ranks:\n",
      "('calibrated_marginal_auprc', 0), average auPRC = 0.9610071969979286\n",
      "('uncalibrated_prob_distance_point_five', 1), average auPRC = 0.9608642133496025\n",
      "('uncalibrated_posterior_uncertainty', 2), average auPRC = 0.9604540124125366\n",
      "('calibrated_prob_distance_point_five', 3), average auPRC = 0.9603676576786583\n",
      "('calibrated_marginal_auroc', 4), average auPRC = 0.9601084827812619\n",
      "('recursive_calibrated_marginal_auprc', 5), average auPRC = 0.9597821649781879\n",
      "('calibrated_posterior_uncertainty', 6), average auPRC = 0.9596700271476483\n",
      "('recursive_calibrated_marginal_auroc', 7), average auPRC = 0.9596323455554472\n",
      "('random', 8), average auPRC = 0.9539503135882064\n",
      "('preactivation_uncertainty', 9), average auPRC = 0.9509329742715839\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "print(\"\\nBest auROC methods - test\")\n",
    "metric_to_auroc_test_score = defaultdict(lambda: 0)\n",
    "metric_name_ranks = sorted(metric_to_method_name_to_test_perfs['auROC'].keys(),\n",
    "                           key=lambda x: -metric_to_method_name_to_test_perfs['auROC'][x][0])\n",
    "for idx, name in enumerate(metric_name_ranks):\n",
    "        metric_to_auroc_test_score[name] += idx\n",
    "print(\"AuROC ranks:\")\n",
    "print(\"\\n\".join(str(x)\n",
    "                +\", average auROC = \"\n",
    "                +str(np.mean(metric_to_method_name_to_test_perfs['auROC'][x[0]]))\n",
    "                for x in sorted(metric_to_auroc_test_score.items(), key=lambda x: x[1])))\n",
    "\n",
    "print(\"\\nBest auPRC methods - test\")\n",
    "metric_to_auprc_test_score = defaultdict(lambda: 0)\n",
    "metric_name_ranks = sorted(metric_to_method_name_to_test_perfs['auPRC'].keys(),\n",
    "                           key=lambda x: -metric_to_method_name_to_test_perfs['auPRC'][x][0])\n",
    "for idx, name in enumerate(metric_name_ranks):\n",
    "        metric_to_auprc_test_score[name] += idx\n",
    "print(\"AuPRC ranks:\")\n",
    "print(\"\\n\".join(str(x)\n",
    "                +\", average auPRC = \"\n",
    "                +str(np.mean(metric_to_method_name_to_test_perfs['auPRC'][x[0]]))\n",
    "                for x in sorted(metric_to_auprc_test_score.items(), key=lambda x: x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
